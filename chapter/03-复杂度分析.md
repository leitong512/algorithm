# 复杂度分析：如何分析、统计算法的执行效率和资源消耗

## 时间复杂度分析

1. 只关注循环执行次数最多的一段代码

2. 加法法则：总复杂度等于量级最大的那段代码的复杂度

3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

## 几种常见时间复杂度
    
![time_complex](../images/03-01.png)

- 上图粗略分为两类，多项式量级和非多项式量级。非多项式量级只有两个：`O(2^n)`和`O(n!)`

1. O(1)
    `O(1)`只是常量级时间复杂度的一种表示方法，并不是指只执行了一行代码。只要代码的执行时间不随 `n` 的增大而增大，这样的代码
   时间复杂度都记作 `O(1)`
   
2. O(logn)、O(nlogn)
    ```
    i = 1；
    while (i <= n) {
        i = i * 2
   }
    ```
   如何求复杂度？ 2^0 ... 2^1  ...  2^x = n  故 x = logn, 时间复杂度O(logn)

3. O(m + n), O(m*n)
   `m`和`n`是表示两个数据规模，实现无法评估`m`和`n`谁的量级大
   
## 空间复杂度分析

空间复杂度表示存储空间与数据规模之间的增长关系，常见的空间复杂度就是`O(1)`、`O(n)`、`O(n^2)`

## 浅析最好、最坏、平均、均摊时间复杂度

1. 最好、最坏情况时间复杂度
    在理想情况下，执行这段代码的时间复杂度为最好时间复杂度；在最糟糕的情况下，执行这段代码的时间复杂度为最快时间复杂度。
   
2. 平均时间复杂度
    
3. 均摊时间复杂度
    ```
    // array 表示一个长度为 n 的数组
    // 代码中的 array.length 就等于 n
    int[] array = new int[n];
    int count = 0;
    void insert(int val) {
        if(count == array.length) {
            int sum = 0;
            for (int i = 0; i < array.lenght;i++) {
                sum += array[i]
            }
            array[0] = sum;
            count = 1;
        }
        array[count] = val;
        ++count;
   }
    ```
   这段代码实现了往数组中插入数据的功能，当数组满了之后，清空数组，然后在继续插入
   最理想的情况：数组有空闲空间，最好时间复杂度`O(1)`
   最坏情况：数组没有空闲空间，最坏时间复杂度`O(1)`
   平均时间复杂度：`O(1)` 加权平均计算
   
    数组插入数据，每一次`O(n)`的插入操作，都会跟着`n-1`此`O(1)`的插入操作，所以把耗时多的那次操作均摊到接下来的`n-1`次耗时少
   的操作上，均摊下来，这一组连续的操作均摊时间复杂度就是`O(1)`。这大致就是均摊分析的思路。
   - 应用场景：
     对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的
     时序关系，这个时候，我们可以将一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的
     操作上。在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。
     
